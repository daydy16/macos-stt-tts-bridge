# macOS STT/TTS Bridge ğŸ¤ğŸ”Š

> âš ï¸ **Experimentell & AI-generiert** - Dieses Projekt wurde mit AI-UnterstÃ¼tzung entwickelt und befindet sich in aktiver Entwicklung. Bugs sind zu erwarten!

Native macOS Server-Anwendung, die Apples hochwertige Speech Recognition und Text-to-Speech Engines Ã¼ber eine HTTP/WebSocket API zugÃ¤nglich macht. Perfekt fÃ¼r **Home Assistant** und andere lokale Automatisierungssysteme.

## âœ¨ Features

- ğŸ¯ **Native macOS Speech Recognition** - Nutzt Apples eingebaute Speech Framework
- ğŸ—£ï¸ **High-Quality TTS** - NatÃ¼rlich klingende Sprachausgabe in vielen Sprachen
- âš¡ **Streaming STT** - WebSocket-basiertes Echtzeit-Streaming fÃ¼r minimale Latenz
- ğŸ”’ **100% Lokal & Privat** - Keine Cloud, alle Daten bleiben auf deinem Mac
- ğŸ  **Home Assistant Integration** - Fertige Custom Component verfÃ¼gbar
- ğŸ¨ **UI & Headless Modi** - Mit oder ohne grafische OberflÃ¤che nutzbar
- ğŸŒ **Multi-Language** - UnterstÃ¼tzt alle von macOS unterstÃ¼tzten Sprachen

## ğŸš€ Quick Start

### Installation

1. **App herunterladen:**
   ```bash
   # Lade die neueste Version von Releases
   # Entpacke und verschiebe nach /Applications
   ```

2. **Mit UI starten:**
   - Doppelklick auf `STTBridge.app`
   - Erlaube Mikrofon-Zugriff wenn gefragt

3. **Headless starten (ohne UI):**
   ```bash
   /Applications/STTBridge.app/Contents/MacOS/STTBridge --headless
   ```

### Als Service installieren

Automatischer Start beim Login:

```bash
# In das Projektverzeichnis wechseln
cd /pfad/zu/STTBridge

# Service installieren
./install-service.sh
```

**Service-Befehle:**
```bash
# Status prÃ¼fen
launchctl list | grep sttbridge

# Stoppen
launchctl unload ~/Library/LaunchAgents/io.github.daydy16.sttbridge.plist

# Starten
launchctl load ~/Library/LaunchAgents/io.github.daydy16.sttbridge.plist

# Logs ansehen
tail -f /tmp/sttbridge.log
```

## ğŸ“¡ API Endpoints

### HTTP Endpoints

**Speech-to-Text (HTTP POST):**
```bash
curl -X POST http://localhost:8787/stt \
  -H "Content-Type: audio/wav" \
  -H "X-Language: de-DE" \
  -H "X-Sample-Rate: 16000" \
  -H "X-Channel-Count: 1" \
  --data-binary @audio.wav
```

**Text-to-Speech:**
```bash
curl "http://localhost:8787/tts?text=Hallo%20Welt&lang=de-DE" -o output.wav
```

**VerfÃ¼gbare Stimmen:**
```bash
curl http://localhost:8787/voices
```

### WebSocket Streaming STT

FÃ¼r Echtzeit-Spracherkennung:

```javascript
const ws = new WebSocket('ws://localhost:8787/stt/stream?lang=de-DE');

ws.onopen = () => {
  // Start message
  ws.send(JSON.stringify({
    type: 'start',
    sampleRate: 16000,
    channels: 1,
    language: 'de-DE'
  }));
  
  // Stream audio chunks
  audioChunks.forEach(chunk => ws.send(chunk));
  
  // End stream
  ws.send(JSON.stringify({ type: 'end' }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'partial') {
    console.log('Partial:', data.text);
  } else if (data.type === 'final') {
    console.log('Final:', data.text);
  }
};
```

## ğŸ  Home Assistant Integration

### Installation

1. **HACS Installation (empfohlen):**
   - FÃ¼ge `https://github.com/daydy16/ha-local-macos-tts-stt` als Custom Repository hinzu
   - Installiere "STT/TTS Bridge"
   - Starte Home Assistant neu

2. **Manuelle Installation:**
   ```bash
   cd config/custom_components
   git clone https://github.com/daydy16/ha-local-macos-tts-stt sttbridge
   ```

### Konfiguration

1. Gehe zu **Einstellungen â†’ GerÃ¤te & Dienste**
2. Klicke **+ Integration hinzufÃ¼gen**
3. Suche nach "STT/TTS Bridge"
4. Gib Host und Port ein (Standard: `localhost:8787`)

### Nutzung in Assist Pipeline

1. **Einstellungen â†’ Voice Assistants â†’ Assist**
2. WÃ¤hle bei Speech-to-Text: `STT/TTS Bridge STT`
3. WÃ¤hle bei Text-to-Speech: `STT/TTS Bridge TTS`
4. Sprache: `de-DE` oder gewÃ¼nschte Sprache

## âš™ï¸ Konfiguration

Die App nutzt Standard-Einstellungen, die fÃ¼r die meisten Anwendungen funktionieren:

- **Host:** `127.0.0.1` (localhost)
- **Port:** `8787`
- **Auth Token:** Optional (kann in Config.swift gesetzt werden)
- **Default Language:** `de-DE`

Zum Anpassen editiere `STTBridge/Server/Config.swift` und kompiliere neu.

## ğŸ”§ Entwicklung

### Voraussetzungen

- macOS 13.0+
- Xcode 15.0+
- Swift 5.9+

### Build von Source

```bash
# Repository klonen
git clone https://github.com/daydy16/macos-stt-tts-bridge.git
cd macos-stt-tts-bridge

# In Xcode Ã¶ffnen
open STTBridge.xcodeproj

# Build & Run in Xcode (Cmd+R)
```

### Projektstruktur

```
STTBridge/
â”œâ”€â”€ STTBridgeApp.swift      # Main App & UI Toggle
â”œâ”€â”€ ContentView.swift        # SwiftUI Interface
â”œâ”€â”€ Server/
â”‚   â”œâ”€â”€ HTTPServer.swift     # HTTP/WebSocket Server
â”‚   â”œâ”€â”€ STTEngine.swift      # Speech Recognition
â”‚   â”œâ”€â”€ TTSEngine.swift      # Text-to-Speech
â”‚   â”œâ”€â”€ Config.swift         # Configuration
â”‚   â””â”€â”€ Models.swift         # Data Models
â””â”€â”€ Webroot/                 # Test Web UI
    â”œâ”€â”€ index.html
    â”œâ”€â”€ app.js
    â””â”€â”€ styles.css
```

## ğŸ› Bekannte Probleme

- [ ] Performance bei sehr langen Audio-Streams kÃ¶nnte optimiert werden
- [ ] Keine UnterstÃ¼tzung fÃ¼r Batch-Verarbeitung
- [ ] Auth-Token Implementierung ist basic

## ğŸ¤ Contributing

Dieses Projekt ist experimentell und wurde grÃ¶ÃŸtenteils AI-generiert. Contributions sind willkommen!

1. Fork das Repository
2. Erstelle einen Feature Branch (`git checkout -b feature/amazing-feature`)
3. Commit deine Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. Push zum Branch (`git push origin feature/amazing-feature`)
5. Ã–ffne einen Pull Request

## ğŸ“ Lizenz

MIT License - siehe [LICENSE](LICENSE) Datei

## ğŸ™ Credits

- Entwickelt mit â¤ï¸ und AI-UnterstÃ¼tzung
- Nutzt Apples Speech Framework und AVFoundation
- Inspiriert von Wyoming Protocol und Rhasspy

## âš ï¸ Disclaimer

Dies ist ein experimentelles Projekt, das mit AI-UnterstÃ¼tzung entwickelt wurde. 
Es wird "as-is" bereitgestellt ohne Garantien. Nutze es auf eigenes Risiko!

---

**GefÃ¤llt dir das Projekt? Star it! â­**
